{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8P/Og+jrp2Mp9TJdFJ5Ee",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mech123/Data-engineering/blob/main/Pyspark_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7gh8xSR2cF5E"
      },
      "outputs": [],
      "source": [
        "# Install Java\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download and extract Spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.5-bin-hadoop3.tgz\n",
        "!mv spark-3.5.5-bin-hadoop3 spark\n",
        "\n",
        "# Install findspark\n",
        "!pip install -q findspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark\"\n"
      ],
      "metadata": {
        "id": "3Vfan36Oc0q9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Colab PySpark\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "bONPu8eHdpA8",
        "outputId": "54d62d67-91fc-4633-87de-417fac582e92"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a3c42e68790>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://146db206bd56:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab PySpark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame\n",
        "data = [('James','','Smith','1991-04-01','M',3000),\n",
        "  ('Michael','Rose','','2000-05-19','M',4000),\n",
        "  ('Robert','','Williams','1978-09-05','M',4000),\n",
        "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
        "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
        "]\n",
        "\n",
        "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
        "df = spark.createDataFrame(data=data, schema = columns)\n"
      ],
      "metadata": {
        "id": "dVACoP6Kd6cK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnH41dvqgPut",
        "outputId": "818d4157-bbe7-4a45-c7ba-482ec30ebd59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7kVO6mEgRiM",
        "outputId": "bb4fc655-71df-40b0-ef8a-1e7c68f143c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV File from the \"sample\" folder\n",
        "df = spark.read.csv(\"/content/sample_data/zipcodes.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Print the schema\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ldg6QKmEt0OD",
        "outputId": "4cd639db-0552-46e9-d360-d5ecc4f1d096"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- RecordNumber: integer (nullable = true)\n",
            " |-- Zipcode: integer (nullable = true)\n",
            " |-- ZipCodeType: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- LocationType: string (nullable = true)\n",
            " |-- Lat: double (nullable = true)\n",
            " |-- Long: double (nullable = true)\n",
            " |-- Xaxis: double (nullable = true)\n",
            " |-- Yaxis: double (nullable = true)\n",
            " |-- Zaxis: double (nullable = true)\n",
            " |-- WorldRegion: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- LocationText: string (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- Decommisioned: boolean (nullable = true)\n",
            " |-- TaxReturnsFiled: integer (nullable = true)\n",
            " |-- EstimatedPopulation: integer (nullable = true)\n",
            " |-- TotalWages: integer (nullable = true)\n",
            " |-- Notes: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read multiple CSV files\n",
        "df = spark.read.csv(\"path/file1.csv,path/file2.csv,path/file3.csv\")\n",
        "\n",
        "\n",
        "# Read all files from a directory\n",
        "df = spark.read.csv(\"Folder path\")\n",
        "\n",
        "\n",
        "# Using delimiter option\n",
        "df3 = spark.read.options(delimiter=',') \\\n",
        "  .csv(\"/path/zipcodes.csv\")\n",
        "\n",
        "# Using inferschema and delimiter\n",
        "df4 = spark.read.options(inferSchema='True',delimiter=',') \\\n",
        "  .csv(\"/path/zipcodes.csv\")\n",
        "\n",
        "\n",
        "\n",
        "# Chaining multiple options\n",
        "df4 = spark.read.option(\"inferSchema\",True) \\\n",
        "                .option(\"delimiter\",\",\") \\\n",
        "  .csv(\"/path/zipcodes.csv\")\n",
        "\n",
        "# Using header option\n",
        "df3 = spark.read.options(header='True', inferSchema='True', delimiter=',') \\\n",
        "  .csv(\"/path/zipcodes.csv\")\n",
        "  "
      ],
      "metadata": {
        "id": "VmiWiOCTv0Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading CSV files with a user-specified custom schema in PySpark involves defining the schema explicitly before loading the data\n",
        "# Imports\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "from pyspark.sql.types import ArrayType, DoubleType, BooleanType\n",
        "\n",
        "# Using custom schema\n",
        "schema = StructType() \\\n",
        "      .add(\"RecordNumber\",IntegerType(),True) \\\n",
        "      .add(\"Zipcode\",IntegerType(),True) \\\n",
        "      .add(\"ZipCodeType\",StringType(),True) \\\n",
        "      .add(\"City\",StringType(),True) \\\n",
        "      .add(\"State\",StringType(),True) \\\n",
        "      .add(\"LocationType\",StringType(),True) \\\n",
        "      .add(\"Lat\",DoubleType(),True) \\\n",
        "      .add(\"Long\",DoubleType(),True) \\\n",
        "      .add(\"Xaxis\",IntegerType(),True) \\\n",
        "      .add(\"Yaxis\",DoubleType(),True) \\\n",
        "      .add(\"Zaxis\",DoubleType(),True) \\\n",
        "      .add(\"WorldRegion\",StringType(),True) \\\n",
        "      .add(\"Country\",StringType(),True) \\\n",
        "      .add(\"LocationText\",StringType(),True) \\\n",
        "      .add(\"Location\",StringType(),True) \\\n",
        "      .add(\"Decommisioned\",BooleanType(),True) \\\n",
        "      .add(\"TaxReturnsFiled\",StringType(),True) \\\n",
        "      .add(\"EstimatedPopulation\",IntegerType(),True) \\\n",
        "      .add(\"TotalWages\",IntegerType(),True) \\\n",
        "      .add(\"Notes\",StringType(),True)\n",
        "\n",
        "df_with_schema = spark.read.format(\"csv\") \\\n",
        "      .option(\"header\", True) \\\n",
        "      .schema(schema) \\\n",
        "      .load(\"/content/sample_data/zipcodes.csv\")"
      ],
      "metadata": {
        "id": "cY8KwpvFv456"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save DataFrame to CSV File\n",
        "df.write.option(\"header\",True) \\\n",
        " .csv(\"/tmp/spark_output/zipcodes\")\n",
        "\n",
        "\n",
        "# Using write options\n",
        "df2.write.options(header='True', delimiter=',') \\\n",
        " .csv(\"/tmp/spark_output/zipcodes\")\n",
        "\n",
        "header: Specifies whether to include a header row with column names in the CSV file.\n",
        "Example: option(\"header\", \"true\").\n",
        "delimiter: Specifies the delimiter to use between fields in the CSV file.\n",
        "Example: option(\"delimiter\", \",\").\n",
        "quote: Specifies the character used for quoting fields in the CSV file. Example: option(\"quote\", \"\\\"\").\n",
        "escape: Specifies the escape character used in the CSV file.\n",
        "Example: option(\"escape\", \"\\\\\").\n",
        "nullValue: Specifies the string to represent null values in the CSV file.\n",
        "Example: option(\"nullValue\", \"NA\").\n",
        "dateFormat: Specifies the date format to use for date columns.\n",
        "Example: option(\"dateFormat\", \"yyyy-MM-dd\").\n",
        "mode: Specifies the write mode for the output. Options include “overwrite”, “append”, “ignore”, and “error”.\n",
        "Example: option(\"mode\", \"overwrite\").\n",
        "compression: Specifies the compression codec to use for the output file.\n",
        "Example: option(\"compression\", \"gzip\")."
      ],
      "metadata": {
        "id": "YttZ68aYz6Xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_schema.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsromMetz8V0",
        "outputId": "5e9f9e10-dc19-428d-eb1f-6ec78fa005c0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- RecordNumber: integer (nullable = true)\n",
            " |-- Zipcode: integer (nullable = true)\n",
            " |-- ZipCodeType: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- LocationType: string (nullable = true)\n",
            " |-- Lat: double (nullable = true)\n",
            " |-- Long: double (nullable = true)\n",
            " |-- Xaxis: integer (nullable = true)\n",
            " |-- Yaxis: double (nullable = true)\n",
            " |-- Zaxis: double (nullable = true)\n",
            " |-- WorldRegion: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- LocationText: string (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- Decommisioned: boolean (nullable = true)\n",
            " |-- TaxReturnsFiled: string (nullable = true)\n",
            " |-- EstimatedPopulation: integer (nullable = true)\n",
            " |-- TotalWages: integer (nullable = true)\n",
            " |-- Notes: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}